{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "objrecogImg1 = \"Blured.jpeg\"\n",
    "objrecogImg2 = \"IMG_2291.jpeg\"\n",
    "\n",
    "objectMask1 = \"car_1.png\"\n",
    "objectMask2 = \"car_4.png\"\n",
    "\n",
    "sktlimg1 = \"\"\n",
    "sktlimg2masks = [\"person_1.png\",\"person_2.png\"]\n",
    "\n",
    "car =\"\"\n",
    "rndobj = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Seg Out Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16456\\3901651075.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Package Import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDefaultPredictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMetadataCatalog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\detectron2\\engine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# prefer to let hooks and defaults live in separate namespaces (therefore not in __all__)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# but still make them available here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdefaults\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\detectron2\\engine\\hooks.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mflatten_results_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLRMultiplier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevents\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEventStorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEventWriter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\detectron2\\evaluation\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcityscapes_evaluation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCityscapesInstanceEvaluator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCityscapesSemSegEvaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcoco_evaluation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCOCOEvaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrotated_coco_evaluation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRotatedCOCOEvaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mevaluator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDatasetEvaluator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetEvaluators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minference_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minference_on_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\detectron2\\evaluation\\cityscapes_evaluation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMetadataCatalog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_io\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPathManager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\detectron2\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m  \u001b[1;31m# isort:skip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m from .build import (\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mbuild_batch_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mbuild_detection_test_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\detectron2\\data\\build.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfigurable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBoxMode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_world_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseed_all_rng\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\detectron2\\structures\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0minstances\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInstances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mkeypoints\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKeypoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheatmaps_to_keypoints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmasks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBitMasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPolygonMasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolygons_to_bitmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mROIMasks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrotated_boxes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRotatedBoxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrotated_boxes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpairwise_iou\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpairwise_iou_rotated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\detectron2\\structures\\masks.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mROIAlign\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mretry_if_cuda_oom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\detectron2\\layers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbatch_norm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFrozenBatchNorm2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNaiveSyncBatchNorm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdeform_conv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeformConv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModulatedDeformConv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmask_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpaste_masks_in_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbatched_nms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched_nms_rotated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnms_rotated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\detectron2\\layers\\deform_conv.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0monce_differentiable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pair\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeform_conv2d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_C\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\torchvision\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\torchvision\\datasets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_optical_flow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFlyingChairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlyingThings3D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHD1K\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKittiFlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSintel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m from ._stereo_matching import (\n\u001b[0;32m      3\u001b[0m     \u001b[0mCarlaStereo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mCREStereo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mETH3DStereo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\torchvision\\datasets\\_optical_flow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_read_png_16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_read_pfm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_str_arg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVisionDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\torchvision\\io\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mVideoMetaData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 22\u001b[1;33m from .image import (\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mdecode_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mdecode_jpeg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\torchvision\\io\\image.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0m_load_library\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Failed to load image Python extension: {e}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\torchvision\\extension.py\u001b[0m in \u001b[0;36m_load_library\u001b[1;34m(lib_name)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0m_kernel32\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"kernel32.dll\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_last_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_kernel32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"LoadLibraryExW\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0m_kernel32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadLibraryExW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0x00001100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LoadLibraryExW is missing in kernel32.dll\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Package Import\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "from detectron2 import model_zoo\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "### --- Code From : https://www.youtube.com/watch?v=Pb3opEFP94U --- ###\n",
    "\n",
    "class Detector:\n",
    "    def __init__(self,model_type):\n",
    "        self.cfg = get_cfg()\n",
    "        self.moodel_type = model_type\n",
    "        \n",
    "    \n",
    "        if model_type == \"OD\":\n",
    "            self.cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "            self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
    "        elif model_type == \"IS\":\n",
    "            self.cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "            self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "        elif model_type == \"PS\":\n",
    "            self.cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n",
    "            self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")\n",
    "\n",
    "        self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "        self.cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "        self.predictor = DefaultPredictor(self.cfg)\n",
    "\n",
    "### --- Code From : https://www.youtube.com/watch?v=Pb3opEFP94U --- ###\n",
    "        \n",
    "# Code below is based on X \n",
    "        \n",
    "    #Perform object detection/segmentation on image\n",
    "    def onImage(self, imagePath,masks_path):\n",
    "        #Read Image to np array\n",
    "        image = cv2.imread(imagePath)\n",
    "        #If model type is panoptic segementation\n",
    "        if self.moodel_type != \"PS\":\n",
    "            # Create predictions for specifed image\n",
    "            predictions = self.predictor(image)\n",
    "            \n",
    "            #Initializes a visualizer with BGR converted image, dataset metadata, and sets instance visualization mode to black and white\n",
    "            viz = Visualizer(image[:,:,::-1], metadata = MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]),\n",
    "            instance_mode = ColorMode.IMAGE_BW)\n",
    "\n",
    "            #Get models predictions, using CPU.\n",
    "            direct_outputs = predictions[\"instances\"].to(\"cpu\")\n",
    "\n",
    "            #Draws model's predictions on the image.\n",
    "            output = viz.draw_instance_predictions(direct_outputs)\n",
    "\n",
    "            #Get the metadata catalog for this configuration\n",
    "            metadata = MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0])\n",
    "            #Get the class list for 'things'\n",
    "            class_names = metadata.thing_classes\n",
    "\n",
    "            #Create an array for the data to be written to the json\n",
    "            data_to_save = []\n",
    "            #For each of the outputs (predictions)\n",
    "            for i in range(len(direct_outputs)):\n",
    "                #Create a predictions dict with the bounding box, label and score\n",
    "                pred = {\n",
    "                    \"bbox\": direct_outputs.pred_boxes.tensor.numpy()[i].tolist(),\n",
    "                    \"label\": class_names[direct_outputs.pred_classes[i].item()],\n",
    "                    \"score\": direct_outputs.scores[i].item(),\n",
    "                }\n",
    "                #Appepnd the predictions to the array\n",
    "                data_to_save.append(pred)\n",
    "\n",
    "        # If model selected is not panoptic segmentation\n",
    "        else:\n",
    "            # Create predictions for specifed image, using panoptic segmenation\n",
    "            predictions, segementInfo = self.predictor(image)[\"panoptic_seg\"]\n",
    "            # Initializes a visualizer with BGR converted imagea and dataset metadata\n",
    "            viz = Visualizer(image[:,:,::-1],MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]))\n",
    "            # Draws model's predictions on the image.\n",
    "            output = viz.draw_panoptic_seg_predictions(predictions.to(\"cpu\"),segementInfo)\n",
    "            # Get the metadata catalog for this configuration\n",
    "            metadata = MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0])\n",
    "            # Get the class list for 'things'\n",
    "            thing_classes = metadata.thing_classes\n",
    "            # Get the class list for 'stuff'\n",
    "            stuff_classes = metadata.stuff_classes\n",
    "\n",
    "            #Create an array for the data to be written to the json\n",
    "            data_to_save = []\n",
    "\n",
    "            # For each of the segements detected\n",
    "            for segment_info in segementInfo:\n",
    "                #If the current segement is a part of the 'thing' class\n",
    "                if segment_info[\"isthing\"]:  # Check if the segment is a \"thing\"\n",
    "                    # ID of the the current segement from the 'thing' class\n",
    "                    category_id = segment_info[\"category_id\"]\n",
    "                    # Human label for the current 'thing' i.e person\n",
    "                    label = thing_classes[category_id] \n",
    "                    # Unqiue id for this 'stuff'\n",
    "                    segment_id = segment_info[\"id\"]\n",
    "\n",
    "\n",
    "                    # Create a mask for the current segment\n",
    "                    mask = predictions == segment_id\n",
    "                    mask_np = np.array(mask.cpu(), dtype=np.uint8)  # Mask with 1s for the object\n",
    "\n",
    "                    # Find contours in the mask\n",
    "                    contours, _ = cv2.findContours(mask_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                    for cnt in contours:\n",
    "                        # Compute the bounding box for the contour\n",
    "                        x, y, w, h = cv2.boundingRect(cnt)\n",
    "                        \n",
    "                        # Bounding box as (x, y, w, h)\n",
    "                        bbox = [x, y, x+w, y+h]  # Format: [x_min, y_min, x_max, y_max]\n",
    "\n",
    "                    # Use the mask to extract the object from the original image\n",
    "                    # Converting to rgb since that was the orginal\n",
    "                    orignal_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    #Create the mask image, removing all pixels \n",
    "                    object_image = cv2.bitwise_and(orignal_image, orignal_image, mask=mask_np)\n",
    "\n",
    "                    # Save the extracted object as an image\n",
    "                    object_image_pil = Image.fromarray(object_image)\n",
    "                    object_image_filename = f\"{label}_{segment_id}.png\"\n",
    "\n",
    "                    # Save the data including the object image filename\n",
    "                    data = {\n",
    "                        \"label\": label,\n",
    "                        \"image\": object_image_filename,\n",
    "                        \"bbox\": bbox\n",
    "                    }\n",
    "                    data_to_save.append(data)\n",
    "                #The current segement must be a part of the 'stuff' class\n",
    "                else:\n",
    "                    # ID of the the current segement from the 'thing' class\n",
    "                    category_id = segment_info[\"category_id\"]\n",
    "                    # Human label for the current 'stuff' i.e sky\n",
    "                    label = stuff_classes[category_id] \n",
    "                    # Unqiue id for this 'thing'\n",
    "                    segment_id = segment_info[\"id\"]\n",
    "\n",
    "                    # Create a mask for the current segment\n",
    "                    mask = predictions == segment_id\n",
    "                    mask_np = np.array(mask.cpu(), dtype=np.uint8)  # Mask with 1s for the object\n",
    "\n",
    "                    # Use the mask to extract the object from the original image\n",
    "                    # Converting to rgb since that was the orginal\n",
    "                    orignal_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    #Create the mask image, removing all pixels \n",
    "                    object_image = cv2.bitwise_and(orignal_image, orignal_image, mask=mask_np)\n",
    "\n",
    "                    # Save the extracted object as an image\n",
    "                    object_image_pil = Image.fromarray(object_image)\n",
    "                    object_image_filename = f\"{label}_{segment_id}.png\"\n",
    "\n",
    "                    # Save the data including the object image filename\n",
    "                    data = {\n",
    "                        \"label\": label,\n",
    "                        \"image\": object_image_filename,\n",
    "                        \"bbox\" : [-1]\n",
    "                    }\n",
    "                    data_to_save.append(data)\n",
    "\n",
    "            #Order the data by the x values in the bounding boxes\n",
    "            data_to_save = sorted(data_to_save,key=lambda item: item['bbox'][0])\n",
    "\n",
    "\n",
    "            #Create an id for each of the entries with a bbox \n",
    "            counter = 0\n",
    "            for i in data_to_save:\n",
    "                if i['bbox'][0] == -1:\n",
    "                    i[\"idNo\"] = -1\n",
    "                else:\n",
    "                    i[\"idNo\"] = counter\n",
    "                    counter += 1\n",
    "\n",
    "        # # Display the results\n",
    "        cv2.namedWindow('Result', cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('Result', 600, 400)\n",
    "        cv2.imshow(\"Result\", output.get_image()[:,:,::-1])\n",
    "        cv2.waitKey(0)   \n",
    "        cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  proposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\n",
      "c:\\Users\\Ossia\\Documents\\SCCUIF\\env\\SCCUIF\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "detectorIS = Detector(model_type=\"IS\")\n",
    "detectorIS.onImage(objrecogImg1,\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text output of colour score in is vs ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  proposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "detectorPS = Detector(model_type=\"PS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Std ps outut inc json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectorPS.onImage(objrecogImg1,\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obj placement output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_placment(df,x):\n",
    "    if(x == 0):\n",
    "        return (0,(df.iloc[x]['label']),(df.iloc[x+1]['label']))\n",
    "    elif (x == len(df)-1):\n",
    "        return ((df.iloc[x-1]['label']),(df.iloc[x]['label']),0)\n",
    "    else:\n",
    "        return (df.iloc[x-1]['label'],(df.iloc[x]['label']),(df.iloc[x+1]['label']))\n",
    "    \n",
    "# Run this in the alog notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sktl with normal vs masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklt std upper and lowerbody outptut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comp folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colour output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get from mainimport cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from skimage.color import rgb2lab,deltaE_cie76,deltaE_ciede2000,deltaE_cmc\n",
    "\n",
    "class HistColour:\n",
    "    def __init__ (self,image_path):\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        #calculating histograms for each channel\n",
    "        self.hue = cv2.calcHist([image],[0], None, [255], [0,255])\n",
    "        self.sat = cv2.calcHist([image],[1], None, [255], [0,255])\n",
    "        self.value = cv2.calcHist([image],[2], None, [255], [0,255])\n",
    "\n",
    "class HistColourPercentage:\n",
    "    def __init__ (self,image_path):\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Calculate the total number of pixels\n",
    "        total_pixels = image.shape[0] * image.shape[1]\n",
    "\n",
    "        hue_value = cv2.calcHist([image],[0], None, [255], [0,255])\n",
    "        sat_value = cv2.calcHist([image],[0], None, [255], [0,255])\n",
    "        val_value = cv2.calcHist([image],[0], None, [255], [0,255])\n",
    "\n",
    "        #calculating histograms for each channel\n",
    "        self.hue = (hue_value/total_pixels) * 100\n",
    "        self.sat = (sat_value/total_pixels) * 100\n",
    "        self.value = (val_value/total_pixels) * 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_distance(image1Name, image2Name):\n",
    "    hist1 = HistColourPercentage(image1Name)\n",
    "    hist2 = HistColourPercentage(image2Name)\n",
    "\n",
    "    hue = np.subtract(hist1.hue,hist2.hue)\n",
    "    sat = np.subtract(hist1.sat,hist2.sat)\n",
    "    value = np.subtract(hist1.value,hist2.value)\n",
    "\n",
    "    hueSquare = np.square(hue)\n",
    "    satSquare = np.square(sat)\n",
    "    valueSquare = np.square(value)\n",
    "\n",
    "    totalAdd = np.add(np.add(hueSquare,satSquare),valueSquare)\n",
    "\n",
    "    return np.average(np.sqrt(totalAdd))\n",
    "\n",
    "\n",
    "\n",
    "def hist_color_intersect(image1Name, image2Name):\n",
    "    img1 = cv2.imread(image1Name)\n",
    "    img2 = cv2.imread(image2Name)\n",
    "    # Convert images to HSV color space\n",
    "    image1_hsv = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)\n",
    "    image2_hsv = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Calculate histograms\n",
    "    hist1 = cv2.calcHist([image1_hsv],[0], None, [255], [0,255])\n",
    "    hist2 = cv2.calcHist([image2_hsv],[0], None, [255], [0,255])\n",
    "\n",
    "    # Normalize histograms\n",
    "    cv2.normalize(hist1, hist1, 0, 1, cv2.NORM_MINMAX)\n",
    "    cv2.normalize(hist2, hist2, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "    hist1 = hist1 / np.sum(hist1)\n",
    "    hist2 = hist2 / np.sum(hist2)\n",
    "    # Compute histogram intersection\n",
    "    intersection = cv2.compareHist(hist1, hist2, cv2.HISTCMP_INTERSECT)\n",
    "\n",
    "    return intersection\n",
    "\n",
    "def lab_space_comp(img1Name,img2Name):\n",
    "    lab_data = []\n",
    "    img1 = rgb2lab(io.imread(img1Name))\n",
    "    img2 = rgb2lab(io.imread(img2Name))\n",
    "\n",
    "    if img1.shape != img2.shape:\n",
    "        img2 = cv2.resize(rgb2lab(io.imread(img2Name)), (img1.shape[:2][1],img1.shape[:2][0]))\n",
    "\n",
    "    #Choose function based on label \n",
    "        # 1: Car\n",
    "        if img1Name.split('_')[0] == \"car\" and img2Name.split('_')[0] == \"car\":\n",
    "            #Show this works better on cars\n",
    "            lab_data = deltaE_ciede2000(img1,img2)\n",
    "        # 2: Person\n",
    "        elif img1Name.split('_')[0] == \"person\" and img2Name.split('_')[0] == \"person\":\n",
    "            #Show this works better on clothes\n",
    "            lab_data = deltaE_cmc(img1,img2)\n",
    "        # 3: Default\n",
    "        else:\n",
    "            lab_data = deltaE_cie76(img1,img2)\n",
    "\n",
    "        return np.average(lab_data)\n",
    "    \n",
    "\n",
    "def lab_space_comp_percentage(img1Name,img2Name):\n",
    "    lab_data = []\n",
    "    img1 = rgb2lab(io.imread(img1Name))\n",
    "    img2 = rgb2lab(io.imread(img2Name))\n",
    "\n",
    "    if img1.shape != img2.shape:\n",
    "        img2 = cv2.resize(rgb2lab(io.imread(img2Name)), (img1.shape[:2][1],img1.shape[:2][0]))\n",
    "\n",
    "    img1 = cv2.normalize(img1, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    img2 = cv2.normalize(img2, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    #Choose function based on label \n",
    "    # 1: Car\n",
    "    if img1Name.split('_')[0] == \"car\" and img2Name.split('_')[0] == \"car\":\n",
    "        lab_data = deltaE_ciede2000(img1,img2)\n",
    "    # 2: Person\n",
    "    elif img1Name.split('_')[0] == \"person\" and img2Name.split('_')[0] == \"person\":\n",
    "        lab_data = deltaE_cmc(img1,img2)\n",
    "    # 3: Default\n",
    "    else:\n",
    "        lab_data = deltaE_cie76(img1,img2)\n",
    "\n",
    "    return np.average(lab_data)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def img_2_img(src,ogImg1Name,ogImg2Name):\n",
    "    img1Name = src + ogImg1Name\n",
    "    img2Name = src + ogImg2Name\n",
    "    img_2_img_comp_data = {\n",
    "       #----Metric 1: Basic Distance \n",
    "        \"comp\" : (\"src= \" + src+ \" : \" + img1Name + \"-\" + img2Name),\n",
    "        \"basic_distance\" :  str(get_distance(img1Name,img2Name)) + \"%\",\n",
    "        \"hist_intersection\" :hist_color_intersect(img1Name,img2Name),\n",
    "        \"lab_space\" : lab_space_comp(img1Name,img2Name)\n",
    "    }\n",
    "    \n",
    "    return img_2_img_comp_data\n",
    "\n",
    "\n",
    "def img_2_all(src,img1Name,imgList):\n",
    "    img2_all_comp_data = {\n",
    "        \"overall_comp\" : (src + \":\" + img1Name),\n",
    "        \"list_comp\" :[]\n",
    "    }\n",
    "    list_img_comp = []\n",
    "    for i in imgList:\n",
    "        list_img_comp.appennd(img_2_img(src,img1Name,i))\n",
    "\n",
    "    img2_all_comp_data[\"list_comp\"] = list_img_comp\n",
    "\n",
    "    return img2_all_comp_data\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab space with and w/o specialistaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from skimage.color import rgb2lab,deltaE_cie76,deltaE_ciede2000,deltaE_cmc\n",
    "\n",
    "def lab_space_comp_percentage_no_spec(img1Name,img2Name):\n",
    "    lab_data = []\n",
    "    img1 = rgb2lab(io.imread(img1Name))\n",
    "    img2 = rgb2lab(io.imread(img2Name))\n",
    "\n",
    "    if img1.shape != img2.shape:\n",
    "        img2 = cv2.resize(rgb2lab(io.imread(img2Name)), (img1.shape[:2][1],img1.shape[:2][0]))\n",
    "\n",
    "    img1 = cv2.normalize(img1, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    img2 = cv2.normalize(img2, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    lab_data = deltaE_cie76(img1,img2)\n",
    "\n",
    "    return np.average(lab_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1197657"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_space_comp_percentage_no_spec(objectMask1,objectMask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12528707"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_space_comp_percentage(objectMask1,objectMask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02167713754441193"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distance(objectMask1,objectMask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9840429269852962"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_color_intersect(objectMask1,objectMask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3292964"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_space_comp_percentage_no_spec(sktlimg2masks[0],sktlimg2masks[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5510889"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_space_comp_percentage(sktlimg2masks[0],sktlimg2masks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Df EXAMPLE OF Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get from algoTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sitting and standing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
